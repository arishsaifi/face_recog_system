{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d89fe1",
   "metadata": {},
   "source": [
    "# **Face Recognition for Attendance System**\n",
    "\n",
    "This Python script uses OpenCV and the `face_recognition` library to create an automated face recognition-based attendance system. The program identifies the employees from a dataset of images and marks their attendance in a CSV file using live webcam footage.\n",
    "\n",
    "### **Dependencies**\n",
    "```bash\n",
    "pip install opencv-python face-recognition numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9407ab21-d724-4744-829d-1c306625b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b52ef",
   "metadata": {},
   "source": [
    "- **cv2**: OpenCV library for handling image and video processing.\n",
    "- **face_recognition**: Library to handle face detection and recognition.\n",
    "- **os**: Module to interact with the file system (for loading datasets).\n",
    "- **numpy**: Library for array manipulation.\n",
    "- **datetime**: To record the time and date when the attendance is marked.\n",
    "- **time**: Used to manage time-related functions.\n",
    "- **pickle**: Python module to serialize and deserialize objects (not used in this snippet).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923916a3",
   "metadata": {},
   "source": [
    "### **1.Load the datset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "050c8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83efd541-2f8b-4b9f-9566-a6d56f15ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store images and class names (employee names)\n",
    "images = []\n",
    "classNames = []\n",
    "\n",
    "# Get the list of folders in the dataset directory\n",
    "folders = os.listdir(path)\n",
    "\n",
    "# Loop through each folder (representing an employee) in the dataset directory\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(path, folder)\n",
    "    \n",
    "    # Check if it's a directory (i.e., a folder for an employee)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # List all images inside the employee's folder\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            curImg = cv2.imread(img_path)\n",
    "            \n",
    "            # Append the image and the employee's name (folder name)\n",
    "            if curImg is not None:\n",
    "                images.append(curImg)\n",
    "                classNames.append(folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff026a65",
   "metadata": {},
   "source": [
    "- **path**: Directory containing folders where each folder corresponds to a person (employee).\n",
    "- **images**: List to store images from the dataset.\n",
    "- **classNames**: List to store the employee names, derived from folder names.\n",
    "The code loops through each folder (employee) and each image inside that folder, storing them in the respective lists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6728428",
   "metadata": {},
   "source": [
    "### **2.Encode Faces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53c17072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the faces from the images\n",
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encoded_face = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encoded_face)\n",
    "    return encodeList\n",
    "encoded_face_train = findEncodings(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ab07c",
   "metadata": {},
   "source": [
    "- **findEncodings()**: Function to convert each image to RGB (required for face_recognition) and encode it using the face_recognition.face_encodings() function. The result is a list of face encodings that will be used to compare faces during live detection.\n",
    "- **encoded_face_train**: List of encoded faces from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83ad407",
   "metadata": {},
   "source": [
    "### **3.Mark Attendance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39c75466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markAttendance(name):\n",
    "    with open('Attendance.csv','r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            time = now.strftime('%I:%M:%S:%p')\n",
    "            date = now.strftime('%d-%B-%Y')\n",
    "            f.writelines(f'n{name}, {time}, {date}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ef455",
   "metadata": {},
   "source": [
    "- **markAttendance()**: This function checks the attendance file Attendance.csv. If the employee’s name is not already in the file, it appends their name, along with the current time and date, indicating attendance has been marked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed605b6",
   "metadata": {},
   "source": [
    "### **4.Real-Time Face Recognition and Attendance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebd2873f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attendance marked for Haris\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start video capture from the default webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize a flag to indicate whether attendance has been marked\n",
    "attendance_done = False\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)  # Scale down the frame\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)  # Convert the frame to RGB format\n",
    "\n",
    "    # Detect face locations and encode the faces in the frame\n",
    "    faces_in_frame = face_recognition.face_locations(imgS)\n",
    "    encoded_faces = face_recognition.face_encodings(imgS, faces_in_frame)\n",
    "\n",
    "    # Loop through each face found in the frame\n",
    "    for encode_face, faceloc in zip(encoded_faces, faces_in_frame):\n",
    "        matches = face_recognition.compare_faces(encoded_face_train, encode_face)\n",
    "        faceDist = face_recognition.face_distance(encoded_face_train, encode_face)\n",
    "\n",
    "        # Find the closest match (smallest distance)\n",
    "        matchIndex = np.argmin(faceDist)\n",
    "\n",
    "        if matches[matchIndex]:\n",
    "            name = classNames[matchIndex].capitalize()  # Capitalize the name\n",
    "\n",
    "            # Get the face location (scaled back to original size)\n",
    "            y1, x2, y2, x1 = faceloc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "\n",
    "            # Draw a rectangle around the detected face\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            \n",
    "            # Draw a filled rectangle for the label below the face\n",
    "            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "            \n",
    "            # Add the name of the recognized employee\n",
    "            cv2.putText(img, name, (x1 + 6, y2 - 5), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "            # Mark the employee's attendance\n",
    "            if not attendance_done:\n",
    "                markAttendance(name)\n",
    "                attendance_done = True  # Set the flag to True once attendance is marked\n",
    "                print(f\"Attendance marked for {name}\")\n",
    "\n",
    "    # Display the webcam feed\n",
    "    cv2.imshow('webcam', img)\n",
    "\n",
    "    # Break the loop if attendance is done or 'q' is pressed\n",
    "    if attendance_done or cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350f3e9c",
   "metadata": {},
   "source": [
    "- **cap = cv2.VideoCapture(0)**: Opens the default webcam.\n",
    "- **Face Detection**: Each frame from the webcam is resized and converted to RGB. face_recognition.face_locations() detects faces, and face_recognition.face_encodings() encodes them.\n",
    "- **Face Matching**: For each detected face, it compares with the trained encodings using face_recognition.compare_faces() and measures the distance to find the closest match.\n",
    "- **Drawing Bounding Box**: A rectangle is drawn around the recognized face, and the employee’s name is displayed.\n",
    "- **Attendance Marking**: Once a face is recognized and attendance is marked, the process stops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cd2690",
   "metadata": {},
   "source": [
    "### **5: Exit and Clean Up**\n",
    "The webcam feed is closed, and all OpenCV windows are destroyed once the process is complete."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
